---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \usepackage{graphicx}
output:
  pdf_document: default
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, comment = NA, fig.align='center')
library(knitr)
library(tidyverse)
source("funciones.R")
```

**Estadística II - Taller 06$\hspace{1.6cm}$Semestre: 2021-02**

**Profesores: Carlos M. Lopera-Gómez y Raúl Alberto Pérez**

**Monitor: Simon Pedro Galeano**

$\rule{6.5in}{1pt}$

1. Responda las siguientes preguntas.
a) En un modelo de regresión es posible que $R^2 = R^{2}_{adj}$, ¿bajo
qué condiciones? ¿Es esto factible en modelos de regresión?
b) Se tiene un modelo de regresión con k covariables, ¿cuál es el
número de observaciones para obtener una estimación de la varianza?.
c) Suponga que se tiene $\underline{\mathbf{x}}_0 = [1, x_{01}, \cdots, x_{0k}]$ adecuado para hacer inferencias respecto a la respuesta media
de $\underline{\mathbf{x}}_0$, ¿la siguiente ecuación es correcta?
$$P\left(0 < \frac{\hat{Y}_0 - \mathbb{E}[Y | \underline{\mathbf{x}}_0| ]}{se(\hat{Y}_0)} < t_{\alpha/2, n-p}\right) = 0.5 - \frac{\alpha}{2} $$
donde $\hat{Y}_0 = \underline{\mathbf{x}}_0  \underline{\mathbf{\beta}}$.

d) Suponga que $\underline{\mathbf{x}}_0 = [1, x_{01}, \cdots, x_{0k}]^T$
es un punto en el que no se comete extrapolación, luego $\underline{\mathbf{x}}_0^T (\mathbf{X}^T\mathbf{X})^{-1} \underline{\mathbf{x}}_0 < 1$.

e) Considere a la entrada $h_{ii}$ de la matriz $\mathbf{H}$, se tiene
que $\sum_{i = 1}^{n} h_{ii}$ es igual al número de covariables en el
modelo.

f) En un modelo de regresión suponga que $2p > n$ y que 
para i = 3 $h_{ii} > \frac{2p}{n}$, ¿dicha observación es un punto de 
balanceo?


2. Considere la siguiente base de datos

\begin{center}
\includegraphics[width=0.7\textwidth]{base.png}
\end{center}

a) Ajuste un modelo de regresión usando la estatura como respuesta y
al resto como covariables (excepto al sexo).

b) Plantee un contraste usando la hipótesis general lineal para comparar
efectos de covariables sobre la respuesta.

c) Valide los supuestos del modelo, encuentre puntos de balanceo e 
influencia, también identifique outliers.

\section{Ejercicio 2}

\begin{center}
\textbf{Solución}
\end{center}

\subsection{a)}

```{r}
url <- "https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo2" #url donde están los datos
datos <- read.table(file=url, sep="\t", header=T)
```

Vamos a ajustar el siguiente modelo de regresión

$$\text{Estatura}_i = \beta_0 + \beta_1 \text{Peso}_i + \beta_2 \text{circuncuello}_i + \beta_3 \text{circunmuneca}_i + \varepsilon_i, \ 1 \leq i \leq 26; \ \varepsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)$$

```{r}
mod <- lm(Estatura ~ Peso + circun_cuello + circun_muneca, data = datos)
```

Una vez ajustado el modelo, se obtuvo la siguiente estimación

$$\hat{\text{Estatura}}_i = 0.7123 + 0.0011 \text{Peso}_i -0.0056 \text{circuncuello}_i + 0.0705 \text{circunmuneca}_i \ 1 \leq i \leq 26$$

\subsection{b)}

Se propone contrastar la hipótesis de que el efecto de las muñecas es igual a la mitad de veces el
del cuello, además, se quiere observar si el efecto del peso es no significativo.

$$
\begin{cases}
\begin{aligned}
H_0 &: 2 \beta_3 = \beta_2, \ \beta_1 = 0 \\
H_1 &: 2 \beta_3 \neq \beta_2, \ \beta_1 \neq 0
\end{aligned}
\end{cases}
$$

Expresando la hipótesis anterior de manera matricial se obtiene que 

$$
\begin{cases}
\begin{aligned}
H_0 &: \mathbf{L} \underline{\beta} = \underline{0} \\
H_1 &: \mathbf{L} \underline{\beta} \neq \underline{0}
\end{aligned}
\end{cases}
$$

donde $L = \begin{bmatrix} 0& 0& -1& 2 \\ 0& 1 & \phantom{-}0& 0\end{bmatrix}$.

Ahora, se especifica el modelo reducido

$$\text{Estatura}_i = \beta_0 + 2\beta_3 \text{circuncuello}_i + \beta_3 \text{circunmuneca}_i + \varepsilon_i, \ 1 \leq i \leq 26; \ \varepsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)$$

lo cual es equivalente a

$$\text{Estatura}_i = \beta_0 + \beta_3(2\text{circuncuello}_i + \text{circunmuneca}_i) + \varepsilon_i, \ 1 \leq i \leq 26; \ \varepsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)$$

o 

$$\text{Estatura}_i = \beta_0 + \beta_3X_{3i} + \varepsilon_i, \ 1 \leq i \leq 26; \ \varepsilon_i \stackrel{iid}{\sim} N(0, \sigma^2)$$

con $X_{3i} = 2\text{circuncuello}_i + \text{circunmuneca}_i$.

```{r}
datos <- datos %>%
  mutate(X3 = 2*circun_cuello + circun_muneca)
modred <- lm(Estatura ~ X3, data = datos)
```

Se tiene que 
\begin{equation*}
\begin{aligned}
F_{0obs} &= \frac{\frac{SSE(RM) - SSE(FM)}{\text{g.l}_{SSE(RM)} - \text{g.l}_{SSE(FM)}}}{MSE} \\
&= \frac{\frac{0.122730 - 0.092836}{24 - 22}}{0.004220} \\
&= 3.541943
\end{aligned}
\end{equation*}

Así, $P(F_{2, 24} >F_{0obs})$ = `r round(pf(3.541943, 2, 24, lower.tail = F),4)` y
por tanto, a un nivel de significancia del 5% se rechaza la hipótesis nula.
\section{d)}

Se procede a validar los supuestos del modelo

```{r}
res.stud <- round(rstandard(mod), 4)
yhat <- round(mod$fitted.values, 4)
# Cálculo de errores estándar de los valores ajustados
se.yhat <- round(predict(mod, se.fit = T)$se.fit, 4)
# Residuales crudos del mod
residuals <- round(mod$residuals, 4)
# Distancias de Cook
Cooks.D <- round(cooks.distance(mod), 4)
# Valores de la diagonal de la matriz H
hii.value <- round(hatvalues(mod), 4)
# Dffits
Dffits <- round(dffits(mod), 4)
# Tabla de diagnósticos
diganosticos <- data.frame(datos, yhat, se.yhat, residuals, res.stud, Cooks.D, hii.value, Dffits)
```

Se analiza la homocedasticidad y los datos atípicos
```{r, fig.cap = "Estudentizados vs ajustados"}
plot(yhat, res.stud, xlab = "Valores Ajustados", 
     ylab = "Residuales Estudentizados", ylim = c(-3.5, 3.5), pch = 20)
abline(h = 0, lty = 2, lwd = 2, col = 2)
abline(h = 3)
abline(h = -3)
```

del gráfico anterior se puede observar claramente una violación del supuesto
de varianza constante y que no se presetan datos atípicos.

Posteriormente se analiza la influencia y el balanceo

```{r, fig.cap="Análisis de influencia"}
with(diganosticos, plot(abs(Dffits),
                        xlab = "Observación", ylab = "Dffits",pch = 20))
abline(h = 2*sqrt(4/26), col = "red")
```

```{r, fig.cap="Análisis de balanceo"}
with(diganosticos, plot(hii.value,
                        xlab = "Observación", ylab = "hii",pch = 20))
abline(h = 2*4/26, col = "red")

```

Respecto a la influencia solo se encuentra una observación, lo cual no es grave ni
representativa, mientras que para el balanceo se tienen 3 observaciones que se
encuentran muy alejadas del resto pero no afectan las estimaciones de los parámetros.

Por último se verifica la normalidad

```{r, fig.cap="Análisis de normalidad"}
myQQnorm(mod)
```

No se ven desviaciones graves del supuesto de normalidad y adicionalmente
el test de Shapiro-Wilk no rechaza la hipótesis de que los residuales vienen
de una población normal.
