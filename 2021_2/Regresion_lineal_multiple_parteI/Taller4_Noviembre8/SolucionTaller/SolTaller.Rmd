---
title: "Taller 4 Solución"
author: "Simón Pedro Galeano Muñoz"
date: "8/11/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```


\section{Ejercicio 1}

\subsection{a)}

La matriz de varianzas-covarianzas siempre es simétrica. (F)

\subsection{b)}

Es falso porque $A \Sigma_y A^{T}$ es la varianza de $A y$ y no 
necesariamente $A$ es la matriz identidad.

\subsection{c)}

Es falso porque las entradas de la diagonal principal son iguales
a 1.

\subsection{d)}

Es verdadero porque es una función lineal de los $\beta$'s.

Además, el modelo es $y_i = \beta_0 + \beta_1x_i + \cdots + \beta_k x_{i}^{k}$ es un modelo con intercepto y polinomial.

\subsection{e)}

$A$ es idempotente sí y solo sí $A^2 = A$.

Consideremos $A^3 = A^2 A = A A = A^2 = A$.
Además, $A^4 = A^3 A = A A = A^2 = A$.
En general si $A$ es idempotente, $A^k = A$.

Adicionalmente si $A$ es simétrica e idempotente, entonces 
$(I_n - A)$ también lo es.

Así la afirmación es verdadera, es decir, $(I_n - A)^n = (I_n - A)$

\section{Ejercicio 2}

Lectura de los datos

```{r}
datos <- MPV::table.b7 #leyendo los datos
datos <- datos %>%
  select(-x4) #excluyendo la variable x4
```

\subsection{a)}
Calculando la matriz de varianzas-covarianzas

```{r}
#con la funcion var se calcula la matriz de varianzas-covarianzas
var(datos)
#tambien se puede hacer cov(datos)
```

\subsection{b)}

Se procede a calcular la matriz de correlaciones

```{r}
cor(datos) #se hace con la funcion cor
```

\subsection{c)}

Se escribe el modelo de regresión lineal múltiple
$$y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 x_{3i} + \beta_5 x_{5i} + \varepsilon_i, \ \varepsilon_i {\stackrel{iid}\sim} N(0, \sigma^2)$$

\subsection{d)}

```{r chunckcito}
datosmat <- as.matrix(datos[, -5]) #excluyendo la respuesta
X <- cbind("intercepto" = 1, datosmat) #añadiendo columna de unos
y <- as.matrix(datos$y) #extrayendo la respuesta
```

\subsection{e)}

```{r}
first <- t(X) %*%  X #multiplicando X^t y X
second <- solve(first) #invirtiedo lo de arriba
third <- second %*% t(X) %*% y #estimacion de los parametros
fourth <- X %*% third #estimacion de la respuesta
fifth <- y - fourth #residuales
```

usando lm
```{r}
mod <- lm(y ~ x1 + x2 + x3 + x5, data = datos) #ajustando el modelo
#se puede usar y ~ . 
```

